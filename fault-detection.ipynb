{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_code_fault_detection_GRP_13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OladotunOlaiya/fault-detection/blob/main/fault-detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qk-4Dn7FCwi"
      },
      "source": [
        "## Dependencies Importation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMDsjvGnP1aN"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "#from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU,Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model,Model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.regularizers import l2,l1,l1_l2\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Input,Dense,Dropout,RepeatVector,TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2,l1,l1_l2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWlz26FTWqY5"
      },
      "source": [
        "seed(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7rTC21TFa_X"
      },
      "source": [
        "## Importing data from various csv files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE37gUZhQHPa"
      },
      "source": [
        "#Mounting google drive location for the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5q3BimrQPsO"
      },
      "source": [
        "file_path ='/content/gdrive/MyDrive/Colab Notebooks/Induction_motor_faults/archive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOSg2YGNQRUi"
      },
      "source": [
        "#Bringing in the dataset into variables \n",
        "normal_files = glob.glob(file_path + \"normal/**/*.csv\", recursive=True)\n",
        "imbalance_fault_files = glob.glob(file_path + \"imbalance/**/*.csv\", recursive=True)\n",
        "#print the loaded csv files\n",
        "print(imbalance_fault_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp-DlS2FFk0n"
      },
      "source": [
        "\n",
        "\n",
        "###Downsampling:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4ITE8jBQaaO"
      },
      "source": [
        "#Reading in the dataset\n",
        "def dataReader(files_array, output_value = 0):\n",
        "    df = pd.DataFrame()\n",
        "    for file in files_array:\n",
        "        df_temp = pd.read_csv(file,header=None,nrows=5000)\n",
        "        df = pd.concat([df,df_temp],ignore_index=True)\n",
        "    df[len(df.columns)] = output_value\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiBzXB8hQg0g"
      },
      "source": [
        "df_normal = dataReader(normal_files, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuOibWuQQl81"
      },
      "source": [
        "df_normal "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpg__9l_vpG6"
      },
      "source": [
        "##Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOctwl0awMbr"
      },
      "source": [
        "Statistical descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npEIuyKGQpIw"
      },
      "source": [
        "df_normal.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7xk8dG8QxK-"
      },
      "source": [
        "# Missing data in columns and rows\n",
        "print(df_normal.isnull().sum(axis = 0),df_normal.isnull().sum(axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPIOK_cAQzoY"
      },
      "source": [
        "#Statistical Description\n",
        "df_normal.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfY5FSyRQ51y"
      },
      "source": [
        "df_imbalance = dataReader(imbalance_fault_files, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8inWBfrHQ9VV"
      },
      "source": [
        "df_imbalance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyDa6emLRAv0"
      },
      "source": [
        "df_imbalance.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBI0HqKNRIQX"
      },
      "source": [
        "# Missing data in columns and rows\n",
        "print(df_imbalance.isnull().sum(axis = 0),df_imbalance.isnull().sum(axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BPPClXIRMLp"
      },
      "source": [
        "df_imbalance.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwg0bNFHRNYd"
      },
      "source": [
        "print (df_normal.shape,df_imbalance.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnLyB4K8wUcg"
      },
      "source": [
        "Data visualization\n",
        "\n",
        "*   correlation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPcihne5v7UZ"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.title('normal_features')\n",
        "sns.heatmap(df_normal.corr(),annot=True,fmt='.2f', square=True,cmap=\"Reds_r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NqenuuGv6vm"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.title('imbalance_features')\n",
        "sns.heatmap(df_imbalance.corr(),annot=True,fmt='.2f', square=True,cmap=\"Reds_r\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg-6Cll_wlWC"
      },
      "source": [
        "#Normal State Features\n",
        "fig, axs = plt.subplots(9, sharex=False, sharey=False,figsize=(15,15))\n",
        "fig.suptitle('Normal State')\n",
        "for i in df_normal.columns:\n",
        "    axs[i].plot(df_normal[i])\n",
        "    axs[i].set_title('{} Column of Dataset'.format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMm50YsewqkQ"
      },
      "source": [
        "#imbalance features\n",
        "fig, axs = plt.subplots(9, sharex=False, sharey=False,figsize=(15,15))\n",
        "fig.suptitle('Imbalance Fault')\n",
        "for i in df_imbalance.columns:\n",
        "    axs[i].plot(df_imbalance[i])\n",
        "    axs[i].set_title('{} Column of Dataset'.format(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU9L2mRCxqnm"
      },
      "source": [
        "\n",
        "\n",
        "*   Box Plots \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nthMf53cx1vb"
      },
      "source": [
        "#Box plot for normal data before normalization\n",
        "boxplot = df_normal.boxplot(rot=45, fontsize=15,figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8iWB7zx1UE"
      },
      "source": [
        "#after scaling:\n",
        "scaler = MinMaxScaler()\n",
        "scaled_df_normal = scaler.fit_transform(df_normal)\n",
        "boxplot = pd.DataFrame(scaled_df_normal).boxplot(rot=45, fontsize=15,figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9QgEdyzBIY"
      },
      "source": [
        "#Box plot for imbalance data before normalization\n",
        "boxplot = df_imbalance.boxplot(rot=45, fontsize=15,figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IMO-uJWx1Ej"
      },
      "source": [
        "#after scaling:\n",
        "scaler = MinMaxScaler()\n",
        "scaled_df_imbalance = scaler.fit_transform(df_imbalance)\n",
        "boxplot = pd.DataFrame(scaled_df_imbalance).boxplot(rot=45, fontsize=15,figsize=(10,10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2FTIA4402PA"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "*   Combining both normal and Imbalance data:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9CVQA6gRZoe"
      },
      "source": [
        "#Join normal and imbalance data frames\n",
        "df_combined = pd.concat([df_normal,df_imbalance],ignore_index=True)\n",
        "df_combined.columns=['SV0','SV1','SV2','SV3','SV4','SV5','SV6','SV7','Y'] # sensor values\n",
        "df_combined_no_label = df_combined.values[:, 0:-1]\n",
        "df_combined.index=pd.to_datetime(df_combined.index,format='%Y-%m-%d %H:%M:%S')# assume data point was generated every \n",
        "df_combined=df_combined.sort_index()\n",
        "\n",
        "labels =df_combined.values[:, -1]\n",
        "df_combined_no_label = df_combined.values[:, 0:-1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypryFgTpKoM6"
      },
      "source": [
        "df_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq3D76LWXUIv"
      },
      "source": [
        "df_combined_no_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJ3tFDfXgo9"
      },
      "source": [
        "\n",
        "\n",
        "*   Split the separate data into train and test:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jr3a4uiXd-k"
      },
      "source": [
        "Normal_data=df_combined_no_label[0:245000]# normal data \n",
        "Normal_labels=labels[0:245000]\n",
        "Imablance_data=df_combined_no_label[245000:]# take 20% of the imbalance data for validation\n",
        "Imbalance_labels=labels[245000:]\n",
        "Normal_data.shape,Imablance_data.shape,Normal_labels.shape,Imbalance_labels.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUSknbp-1iXd"
      },
      "source": [
        "\n",
        " \n",
        "\n",
        "* Split normal into train and test:    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFN7c_rghzh6"
      },
      "source": [
        "#Normal train and test\n",
        "xtrain_normal,x_test_normal,ytrain_normal,ytest_normal=train_test_split(Normal_data,Normal_labels,test_size=0.2,random_state=0)\n",
        "xtrain_normal.shape,ytrain_normal.shape,x_test_normal.shape,ytest_normal.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqlwjHd2BhJ"
      },
      "source": [
        "* Split imbalance into train and test: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuwnzb1Xgmc0"
      },
      "source": [
        "#imbalance data\n",
        "xtrain_imbal,x_test_imbal,ytrain_imbal,ytest_imbal=train_test_split(Imablance_data,Imbalance_labels,test_size=0.2,random_state=0)\n",
        "xtrain_imbal.shape,ytrain_imbal.shape,x_test_imbal.shape,ytest_imbal.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5s5bcUg2GVF"
      },
      "source": [
        "* Split the combined into train and test: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ubGUgW4pf-H"
      },
      "source": [
        "#combined data\n",
        "train_combined,test_combined,ytrain_combined,ytest_combined =train_test_split(df_combined_no_label,labels,test_size=0.2,random_state=20)\n",
        "train_combined.shape,test_combined.shape,ytrain_combined.shape,ytest_combined.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av3NNivCZdwf"
      },
      "source": [
        "\n",
        "\n",
        "*  Scaling and Reshaping the normal data into a tensor:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0bVOlioYmHO"
      },
      "source": [
        "#for the normal data:\n",
        "scaler=MinMaxScaler()\n",
        "x_trainN_scaled=scaler.fit_transform(xtrain_normal)\n",
        "\n",
        "x_testN_scaled=scaler.transform(x_test_normal)\n",
        "x_train_2d=x_trainN_scaled\n",
        "x_trainN_scaled=x_trainN_scaled.reshape(x_trainN_scaled.shape[0],1,x_trainN_scaled.shape[1])\n",
        "print('normal training data shape:',x_trainN_scaled.shape)\n",
        "x_testN_scaled=x_testN_scaled.reshape(x_testN_scaled.shape[0],1,x_testN_scaled.shape[1])\n",
        "print('normal testing data shape:',x_testN_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyzfV9-w2bMK"
      },
      "source": [
        "\n",
        "*  Scaling and Reshaping the imbal data into a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9rs-jfmmKTh"
      },
      "source": [
        "#for the imbalance data:\n",
        "scaler=MinMaxScaler()\n",
        "x_train_imbal_scaled=scaler.fit_transform(xtrain_imbal)\n",
        "x_test_imbal_scaled=scaler.transform(x_test_imbal)\n",
        "x_train_imbal_scaled=x_train_imbal_scaled.reshape(x_train_imbal_scaled.shape[0],1,x_train_imbal_scaled.shape[1])\n",
        "print('imbalance training data shape:',x_train_imbal_scaled.shape)\n",
        "x_test_imbal_scaled=x_test_imbal_scaled.reshape(x_test_imbal_scaled.shape[0],1,x_test_imbal_scaled.shape[1])\n",
        "print('imbalance testing data shape:',x_test_imbal_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWSe9_Cf2hpV"
      },
      "source": [
        "\n",
        "*  Scaling and Reshaping the combined data into a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69u7L90nq4b_"
      },
      "source": [
        "#for the combined data:\n",
        "scaler=MinMaxScaler()\n",
        "train_combined_scaled=scaler.fit_transform(train_combined)\n",
        "test_combined_scaled=scaler.transform(test_combined)\n",
        "train_combined_scaled=train_combined_scaled.reshape(train_combined_scaled.shape[0],1,train_combined_scaled.shape[1])\n",
        "test_combined_scaled=test_combined_scaled.reshape(test_combined_scaled.shape[0],1,test_combined_scaled.shape[1])\n",
        "test_combined_scaled.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWm4vXLa2tY"
      },
      "source": [
        "# LSTM autoencoder model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejtey4z6a2aF"
      },
      "source": [
        "def LSTM_autoencoder(X=x_trainN_scaled,activation='relu',kernel_regularizer=regularizers.L2(0.00)):\n",
        "    print(X.shape)\n",
        "    inputs=Input(shape=(X.shape[1],X.shape[2]))\n",
        "    x=inputs\n",
        "    x=LSTM(16,activation='relu',return_sequences=True,kernel_regularizer=regularizers.L2(0.00))(x)\n",
        "    x=LSTM(4,activation='relu',return_sequences=False)(x)\n",
        "    x=RepeatVector(X.shape[1])(x)\n",
        "    x=LSTM(4,activation='relu',return_sequences=True)(x)\n",
        "    x=LSTM(16,activation='relu',return_sequences=True)(x)\n",
        "    output=TimeDistributed(Dense(X.shape[2]))(x)\n",
        "    model=Model(inputs=inputs,outputs=output)\n",
        "    model.compile(optimizer='adam',loss='mae',metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_zhuYYt3tbT"
      },
      "source": [
        "\n",
        "\n",
        "*   Hyperparameter tuning with Randomsearch\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RyD7oG63syA"
      },
      "source": [
        "model=KerasClassifier(build_fn=LSTM_autoencoder,verbose=1)\n",
        "\n",
        "kernel_regularizer=['L1','L2']\n",
        "epochs=[20,50,100,150]\n",
        "batch_size=[32,64,128,512]\n",
        "activation=['relu','tanh']\n",
        "param_grid=dict(batch_size=batch_size,activation=activation,kernel_regularizer=kernel_regularizer,epochs=epochs)\n",
        "grid=RandomizedSearchCV(estimator=model,param_distributions=param_grid,n_jobs=-1,cv=3,n_iter=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajsRw497W9sn"
      },
      "source": [
        "grid_result=grid.fit(x_trainN_scaled,x_train_2d)\n",
        "print(\"Best: %f using %s\" %(grid_result.best_score_,grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Qd7w1FdwdL"
      },
      "source": [
        "## create and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgpSXGwjdv8L"
      },
      "source": [
        "model=LSTM_autoencoder(x_trainN_scaled)\n",
        "model.compile(optimizer='adam',loss='mae')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHWHcsFJDJLF"
      },
      "source": [
        "## Model Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7foTRMsqdqs1"
      },
      "source": [
        "#training the model:\n",
        "epochs_number=20\n",
        "batch_size=512\n",
        "history = model.fit(x_trainN_scaled,x_trainN_scaled,epochs=epochs_number,batch_size=batch_size,validation_data=(test_combined_scaled,test_combined_scaled),shuffle=True,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxg45a5vtZB"
      },
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RamFXIrMOLRJ"
      },
      "source": [
        "reconstructions = model.predict(x_trainN_scaled)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, x_trainN_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0XYaLa4QJM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjozXAQzOnV9"
      },
      "source": [
        "plt.hist(train_loss[:,0], bins=50)\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzaD21gwDdyN"
      },
      "source": [
        "\n",
        "\n",
        "## Setting threshold\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNmuhVV3v8h_"
      },
      "source": [
        "threshold = np.mean(train_loss) #+ np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWi005PJ8qa-"
      },
      "source": [
        "def predict(model, data, threshold):\n",
        "    reconstructions = model(data)\n",
        "    loss = tf.keras.losses.mae(reconstructions, data)\n",
        "    return tf.math.less(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  #print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  #print(\"Recall = {}\".format(recall_score(labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6OyNtOWDbOS"
      },
      "source": [
        "def predictLabels(autoEncoderModel, inputData, threshold_val):\n",
        "  recon = autoEncoderModel(inputData)\n",
        "  loss_val = tf.keras.losses.mae(recon, inputData)\n",
        "  predictedLabels = tf.math.less(loss_val, threshold_val)\n",
        "  return predictedLabels, loss_val\n",
        "\n",
        "def print_stats_new(predicted_val, inputDataLabels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(inputDataLabels, predicted_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNoaoIuMD4iE"
      },
      "source": [
        "## Prediction accuracy( Not the model accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nRUggdpE7lV"
      },
      "source": [
        "preds_val, loss_values = predictLabels(model, test_combined_scaled, threshold)\n",
        "\n",
        "print_stats_new(preds_val, ytest_combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UI7DR-qN725"
      },
      "source": [
        "preds_val_normal, loss_values_normal = predictLabels(model, x_trainN_scaled, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8dx1tJXGXfM"
      },
      "source": [
        "print_stats_new(preds_val_normal, ytrain_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JS4DZC3QCVz"
      },
      "source": [
        "preds_val_imbalance, loss_values_imbalance = predictLabels(model, x_train_imbal_scaled, threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDHQHuVsII6w"
      },
      "source": [
        "time = np.linspace(0,1,len(test_combined_scaled),endpoint=True)\n",
        "fig, axs = plt.subplots(nrows=1, figsize=(16, 9))\n",
        "\n",
        "#sns.lineplot(x=time, y=loss_values)\n",
        "#plt.plot(loss_values_imbalance[:250], label=\"loss value\", color='r')\n",
        "#plt.plot(loss_values_normal[:250], label=\"normal loss value\", color='g')\n",
        "#plt.plot([100, threshold], label=\"Threshold Value\")\n",
        "\n",
        "#plt.axhline(y=threshold, label=\"Threshold Value\", color='b')\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg0gVElt2J9Y"
      },
      "source": [
        "preds = predict(model, test_combined_scaled, threshold)\n",
        "print_stats(preds, ytest_combined)\n",
        "#preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuIPoaJsVb4g"
      },
      "source": [
        "preds.shape,x_test_imbal_scaled.shape,ytest_imbal.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAJvYpJYWd8Q"
      },
      "source": [
        "#x_test_imbal_scaled.shape[0]\n",
        "\n",
        "preds[0]\n",
        "\n",
        "preds.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjGI5CpxUzBi"
      },
      "source": [
        "#pred_scaled=pd.DataFrame(x_test_imbal_scaled[:,0]) + pd.DataFrame(ytest_imbal[:])\n",
        "\n",
        "#pred_scaled = pd.concat([pd.DataFrame(x_test_imbal_scaled[:,0]), pd.DataFrame(ytest_imbal[:]), pd.DataFrame(preds.numpy())], axis=1, ignore_index=True)\n",
        "pred_scaled = pd.concat([pd.DataFrame(test_combined_scaled[:,0]), pd.DataFrame(ytest_combined[:].astype(int)), pd.DataFrame(preds.numpy().astype(int))], axis=1, ignore_index=True)\n",
        "#pred_scaled=pd.DataFrame(x_test_imbal_scaled[:,0])\n",
        "\n",
        "#pd.DataFrame.set_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Q7u0pOVGek"
      },
      "source": [
        "pred_scaled\n",
        "\n",
        "#pred_scaled\n",
        "\n",
        "#ytest_imbal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EkCXULmn13v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUYF11knzC6"
      },
      "source": [
        "true_count = (pred_scaled[9]).value_counts()[1] \n",
        "False_count = (pred_scaled[9]).value_counts()[0]\n",
        "print(true_count,False_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdnennJvtF9m"
      },
      "source": [
        "#accuracy_count = (pred_scaled[8]).value_counts()\n",
        "\n",
        "accuracy_count = (pred_scaled[pred_scaled[8] == pred_scaled[9]]).value_counts()\n",
        "#true_count_2 = accuracy_count[10].value_counts()[True]\n",
        "print(len(accuracy_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LJ11tDJoVLn"
      },
      "source": [
        "p=(len(accuracy_count)/len(pred_scaled))*100\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M648yaTDq7jM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}